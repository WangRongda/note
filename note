--
\n is linefeed, Ctrl-j or character 012
\r is carriage retrun, Ctrl-M or character 015
--

git:
gitignore ignore untracked file only when tracking to add
已经跟踪的文件不会忽略

.gitignore: 支持通配符
test:
	./test
	./xx/test
	./test/xx
	./xx/test/
/test:
	./test
	./test/xx
test/:
	./test/xx
	./xx/test/
/test/:
	./test/xx

doc/*.pdf:
	./doc/a.pdf
	./doc/b.pdf
doc/*/*.pdf:
	./doc/xx/a.pdf
	./doc/xx/b.pdf
doc/**/*.pdf:
	./doc/a.pdf
	./doc/b.pdf
	./doc/xx/a.pdf
	./doc/xx/b.pdf

git diff --cached/staged: stage(commited)和版本库比较
git diff: working tree(unstaged)和 stage比较,若stage里没有则和版本库比较, 即只要工作区发生改变的,就会有，stage有和stage比较，stage没有和respo比较

git commit -a: 会包括delete

git rm: 会untrack并删除工作区,相当于直接删除工作区文件并git add
git mv: 相当于直接mv文件系统并git add
git rm --cache: 只是untrack文件
git rm \*~: 通配符需要转义，不用bash的

git commit --amend: 一个全新的快照添加并覆盖原来的，原来的被从历史里删除（sha-1摘要变化了), 尽管不再历史里，还是有办法恢复到这个提交（git数据恢复篇)

git checkout file: 清除工作区修改(未add到暂存区的快照叫工作区），比较危险，除非是非常确定的情况下，否则拉个分支再清除比较安全

alpha: 内部版本
beta: 测试版
rc: 即将作为正式版发布
lts: 长期维护

git add: stage快照中对于修改过的文件copy了一份
git commit: 快照直接指向stage,对象里包括这个指针、author's name and email, commit message ...

.git/object：对象库，存放所有对象：文件（该目录最大的原因）（不只是工作目录的文件，只要曾经被add的文件都会被存放，stage快照中修改过的文件被存为新的，未修改被add的直接引用，,,所以包括被修改过的副本，被删除的也会被保留，!!!!只要曾经被add的，校验和不存在的，就会被添加!!!!。 以sha-1校验和区分）; 文件树，存放快照文件结构,包含的指向若干文件对象等; 提交对象，包括tree指针指向前面那个树的校验和，parent指针指向该分支上一个提交对象的校验和,username, email等
tip: 文件被编译为二进制，使用git cat-file <checksum>查看

git checkout -- file: 丢弃工作区的修改，将modified的文件的修改复原（可能复原到和staged的一样，或和版本库一样)
一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；
一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。
总之，就是让这个文件回到最近一次git commit或git add时的状态。

./git/object里不包括staged的快照（tree对象）,stage的信息(目录结构快照)保存在.git/index
使用git ls-files --stage(index文件被编译为二进制文件)查看：
100644 95ef7c6bd1c2d0a7ac268241dd4bd4b1415da423 0       .gitignore
100644 f4bc36652eee71c7e127a40b68137235a2aeb6e4 0       go1.9.2.linux-amd64.tar.gz
100644 529ba277c064f3d312a647eb5247d1ca3421eb6e 0       main.c

当commit后会生成commit的对象和tree对象(文件名为校验和，tree的文件内容如下） 在object目录下，tree对象就是由上面的index得来：
tree对象: 
100644 blob 95ef7c6bd1c2d0a7ac268241dd4bd4b1415da423    .gitignore
100644 blob f4bc36652eee71c7e127a40b68137235a2aeb6e4    go1.9.2.linux-amd64.tar.gz
100644 blob 529ba277c064f3d312a647eb5247d1ca3421eb6e    main.c


linux: ls -lh 
第2个参数: 
1, 若为文件，表示硬链接数
2, 若为目录，表示有多少个子目录（包括.和..，所以至少2, 同时包括隐藏）


git pull origin next:master 取回主机的next分支与本地的master分支合并，省略则与当前分支合并

git push -u origin master: 关联远程（上游）

git push origin <本地分支>:<远程分支>: 远程分支省略则推送到与本地分支对应的上游分支通常为<远程名>/<本地分支名>（本地跟踪远程的分支）, 如果该远程分支不存在，则会被新建（和本地分支同名）
若本地分支为空 git push origin :<远程分支> 则删除远程分支  == git push origin --delete <master>

git push origin 将当前分支推到origin主机对应的分支

go: 一个目录只能有一个包若发现两个包（如同一个目录有两个文件分别为package a, package b)，编译不会通过
一个目录的go文件的包名一般和目录名一样（可以不一样，import的时候import目录，包名还是go文件的包名,容易引起混乱)

go install github.com/test: (或者cd $GOPATH/src/github.com/test && go install)
1. 将$GOPATH/src/github.com/test的源文件进行编译，包编译成.a放到相应的$GOPATH/pkg/github.com/test下，main包编译成可执行文件到bin/test(没有github.com/test)下
go get github.com/test: (会递归clone依赖） go get -u 确保所有包和依赖包都是最新的，然后重新编译安装他们
1. git clone https://github.com/test $GOPATH/github.com/test
2. git install github.com/test



foo := []rune //slice
foo := [3]rune //array
foo := [...]rune //array

unsafe.sizeof([]rune) // 24 ( len(8) + cap(8) + data(8, a point to real array) )
unsafe.sizeof([3]rune) // 12 ( 3 x 4(int32) )

slice = append(slice, element) // 给slice追加一个元素（len加1）， 若cap足够，则直接在原底层数组上, cap不变; 若cap不够，则另外申请一个底层数组（cap可能是原来的两倍或其他策略），将之前的元素copy到新数组，并追加，cap改变; 无论是哪一种，都会将返回 ‘新的’ slice, 就的不变， 通常需要将‘新的’赋给原slice

string: 不可改变的字节序列（只读[]byte）， UTF8编码


字面量：
十进制： 123
八进制： 0327(第一位: 阿拉伯数字 零)
十六进制： 0x32af 

fmt.Printf("
1) %b ：二进制(不会根据变量占有内存在前面补0变成固定长度)
2) %d :	十进制
3) %x : 


golang not allow : 
1) 连等
2) 三元运算符 ?



js: 
0 == "" // true 
0 == "0" //true
0 == "1" //false
0 == [] //true
0 == [0] //true
if ("")  // if (false)
if ([]) // if (true)


快的程序往往是伴随着较少的内存分配


查看某命令（文件）属于哪个包：
pacman -Qo file
查看某软件包的文件信息：
pacman -Ql package
软件包的其他信息：
pacman -Qi package

查看可执行文件依赖的共享库(以gtk/qt为例)：
ldd $(which evince) | grep 'gtk\|qt'
查看进程的调用的动态共享库so：
pmap -p $pid | grep 'gtk|Qt'


test中使用全局是安全的, go test命令并不会同时并发地执行多个测试

生成目标代码（不链接生成可执行）： gcc -c demo.c => demo.o
生成静态链接库: ar rv libx.a x1.o x2.o ..
生成共享库： gcc -shared -o libx.so x1.o x2.o (通常-fPIC)

链接（共享/静）库： gcc -lx main.o -o exe (同时存在libx.a, libx.so,优先so, 默认库gcc_s等以动态形式链接)
强制全部静态链接： gcc -static -lx main.o -o exe (需要libx.a, 包括了动态连接时（不指明static时）的ld.so, gcc_s 等默认共享库都会被静态链接，所以出来的可执行文件较大,完全独立）
部分强制静态链接： gcc -Wl,Bstatic -lx ( 需要带上-Wl,Bdynamic -lgcc_s，否则编译不通过，且这种方法一般没有gcc_s的静态库, 要静态链接这一部分占时用全部静态-static）
动态部分： gcc -Wl,Bdynamic -lx (这会导致-static失效）

静态链接库： .a, 在链接成可执行文件时，静态链接库被链接进程序且运行不再依赖与这个.a
共享库(动态链接）: .so , 链接成可执行文件时指明依赖的共享库，共享库的内容不会被写进程序，运行可执行文件时需要依赖共享库so, 并且在程序启动时就加载(在指明依赖链接库时优先使用共享库，除非强制指明静态链接)
动态加载共享库：void*dlopen (const char *libname, int flag); 不像动态链接的共享库，程序启动时就被ld.so寻找并装载，而是需要的时候由程序函数调用的共享库so

//如果要链接没有lib前缀的库文件，可以直接指定库的全名，无需加-L，-l选项
//另外，当编译可执行文件需要链接多个静态库的情况：
1、静态库是前后依赖关系，则依赖库靠前，被依赖的库靠后，如a依赖b，-la -lb
2、静态库是相互依赖关系，则需要多次添加同一个库，如a依赖b，同时b依赖a，-la -lb -la
3、有没有比较优雅的方式解决第2种情况，有，加链接的属性，如：-Xlinker --start-group -la -lb -Xlinker --end-group

C:
动态库装载：
共享库的寻找和加载是由/lib/ld.so /lib/ld-linux.so实现的，ld.so在标准路径/lib, /usr/lib中寻找应用程序用到的共享库(用到非标准库中库的做法是将非标准库路径加入/etc/ld.so.conf,然后运行ldconfig生成/etc/ld.so.cache。ld.so加载共享库时，会从ld.so.cache查找。ld加载共享库的时候，也会差好LD_LIBRARY_PATH这个环境变量)


ldd(不是一个可执行程序，是一个shell脚本): 打印一个执行程序的 共享库依赖关系。
这个脚本通过设置一系列环境变量:
"LD_TRACE_LOADED_OBJECTS、LD_WARN、LD_BIND_NOW、LD_LIBRARY_VERSION、LD_VERBOSE等。
当LD_TRACE_LOADED_OBJECTS环境变量不为空时，任何可执行程序在运行时，它都会只显示模块的 dependency，而程序并不真正执行"
如 export LD_TRACE_LOADED_OBJECTS=1; ls; 将只显示ls执行程序的依赖共享库。而不执行ls
原理：
通过ld-linux.so动态库装载器实现的,ld-linux.so模块会优先与executable模块程序工作，并获得控制权，因此上述环境变量被设置时，ld-linux.so选择显示可执行模块的依赖
实际上可以直接执行ld-linux.so模块： /lib/ld-linux.so --list program  = ldd program

那程序又是怎么找到ld-linux.so的： ld-linux.so的位置是写死在程序中的，gcc在编译程序时就写死在里面了。gcc写到程序中ld-linux.so的位置是可以改变的，通过修改gcc的spec文件

运行时，ld-linux.so查找共享库的顺序
（1）ld-linux.so.6在可执行的目标文件中被指定，可用readelf命令查看 
（2）ld-linux.so.6缺省在/usr/lib和lib中搜索；当glibc安装到/usr/local下时，它查找/usr/local/lib
（3）LD_LIBRARY_PATH环境变量中所设定的路径 
（4）/etc/ld.so.conf（或/usr/local/etc/ld.so.conf）中所指定的路径，由ldconfig生成二进制的ld.so.cache中

编译时，ld-linux.so查找共享库的顺序
（1）ld-linux.so.6由gcc的spec文件中所设定 
（2）gcc --print-search-dirs所打印出的路径，主要是libgcc_s.so等库。可以通过GCC_EXEC_PREFIX来设定 
（3）LIBRARY_PATH环境变量中所设定的路径，或编译的命令行中指定的-L/usr/local/lib 
（4）binutils中的ld所设定的缺省搜索路径顺序，编译binutils时指定。（可以通过“ld --verbose | grep SEARCH”来查看） 
（5）二进制程序的搜索路径顺序为PATH环境变量中所设定。一般/usr/local/bin高于/usr/bin
（6）编译时的头文件的搜索路径顺序，与library的查找顺序类似。一般/usr/local/include高于/usr/include


=====================================================================
gcc 编译的四大过程（预处理-编译-汇编-链接 ）

     我们来编译一个hello world 程序。

#include <stdio.h>

int main(int argc,const char* argv[])

{

    printf("hello world!\n");

    return 0;

}
1）预处理(Pre-processing)
在该阶段，编译器将C源代码中的包含的头文件如stdio.h编译进来，用户可以使用gcc的选项”-E”进行查看。
用法:#gcc -E main.c -o main.i
作用：将main.c预处理输出main.i文件

[user:test] ls
main.c
[user:test] gcc -E main.c -o main.i
[user:test] ls
main.c  main.i

 

2)编译阶段(Compiling)
第二步进行的是编译阶段，在这个阶段中，Gcc首先要检查代码的规范性、是否有语法错误等，以确定代码的实际要做的工作，在检查无误后，Gcc把代码翻译成汇编语言。用户可以使用”-S”选项来进行查看，该选项只进行编译而不进行汇编，生成汇编代码。
选项 -S
用法：[user]# gcc –S main.i –o main.s
作用：将预处理输出文件main.i汇编成main.s文件。

[user:test] ls
main.c  main.i
[user:test] gcc -S main.i -o main.s
[user:test] ls
main.c  main.i  main.s

3)汇编阶段(Assembling)
汇编阶段是把编译阶段生成的”.s”文件转成二进制目标代码.
选项 -c
用法：[user]# gcc –c main.s –o main.o
作用：将汇编输出文件main.s编译输出main.o文件。

[user:test] ls
main.c  main.i  main.s
[user:test] gcc -c main.s -o main.o
[user:test] ls
main.c  main.i  main.o  main.s

4）链接阶段(Link)
在成功编译之后，就进入了链接阶段。
无选项链接
用法：[user]# gcc main.o –o main.exe
作用：将编译输出文件main.o链接成最终可执行文件main.elf

[user:test] ls
main.c  main.i  main.o  main.s
[user:test] gcc main.o -o main.elf
[user:test] ls
main.c  main.elf*  main.i  main.o  main.s
=======================================================================

go build/install: 当前目录为项目目录
go build/install [pack]: $GOPATH/src/pack为项目目录

golang 项目自己的依赖包（不从互联网上get)
放在项目下的vendor目录
即使使用vendor，也必须在GOPATH中，在go的工具链中，你逃不掉GOPATH的

那么查找依赖包路径的解决方案如下：
    当前项目目录（先检查是否在$GOPATH/src/projec, 也是下面一条的前提)下的vendor目录。
    向上级目录查找，直到找到src下的vendor目录。
    在GOPATH下面查找依赖包。
    在GOROOT目录下查找

在使用vendor中，给出如下建议：

    一个库工程（不包含main的package）不应该在自己的版本控制中存储外部的包在vendor\目录中，除非他们有特殊原因并且知道为什么要这么做。
    在一个应用中，（包含main的package），建议只有一个vendor目录在代码库一级目录。

上面建议的原因如下：

    在目录结构中的每个包的实例，即使是同一个包的同一个版本，都会打到最终的二进制文件中，如果每个人都单独的存储自己的依赖包，会迅速导致生成文件的二进制爆发（binary bloat)
    在一个目录的某个pacage类型，并不兼容在同一个package但是在不同目录的类型，即便是同一个版本的package，那意味着loggers，数据库连接，和其他共享的实例都没法工作。


git 中某git仓库的工作目录下的子目录不能够有自己的git仓库，当一个子目录下有自己的git仓库，则该子目录工作区的所有文件和版本库不会被总版本库添加，若子目录需要有自己的版本控制，则通过子模块,为其添加子模块，总版本库通过.gitmodules知道哪些目录是子版本库，里面记录了子版本库目录以及对应的真实(远程)仓库url,总仓库不包含子模块的任何版本信息（文件，仓库等），当clone一个包含子模块的仓库时，会发现子模块所在目录是空的（工作区，.git仓库, git文件), 只有总工作区有一个.gitmodule文件被保留，需要执行git submodule init(会根据.gitmodules文件将url注册到目录）， git submodule update(这一步会在子目录创建工作区文件和.git文件，git文件记录真实的git的仓库地址，通常在总仓库目录下: .git/modules/相应的目录地址 , 总仓库下的modules目录用于存放所有其他子模块的本地仓库，统一管理（不单独放在他们工作区下）,这个modules目录也是git submodule update时创建的。
.gitmodules文件的url若使用的是相对地址，则是相对总仓库的url，如别人clone这个总仓库时，那么就以clone的url为域名（有趣的是你这么干,子仓库真的存在于子目录下，而子目录任何东西不会被提交，当你push到远程，远程就再也拿不到这个仓库，或者当别人pull你，这个子模块的仓库会作为远程在.git/modules下，结构也不一样，反正种种问题，不建议使用相对地址子模块或者将一个仓库放在另一个仓库的子目录下）

git 子模块：
git submodule add [git地址] [到目录]
会添加远程仓库到但前目录下指定的位置
子模块git仓库不放在自己的仓库目录下，可以ls .git/ 没有这个目录，而有.git这个文件，这个文件指明了实际仓库的位置，cat .git可以看到仓库被放到了父模块的.git总仓库下的modules目录 下。
同时在总仓库下生成一个.gitmodule文件，记录各个子模块项目路径了上游url,只有存在这个文件，git才能知道谁是子模块

git diff: 工作区和stage比或和仓库比
git diff --cached: stage和仓库比


一个可能的包含子模块的tree快照
git cat-file -p 55493783344510bdffa0c63bcedd3a054ac652df
100644 blob 11ae4f2eef95dfe9219cee0d97cb6f372e349be4    .gitmodules
100644 blob 4d51fa4e2aba7d68840dcdb059eca7a1719b8fed    candy.go
100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391    main.go
160000 commit 392d907deb6503fdba6d81a8318662a8e6c36f8e  subcandy

可以看到对于这个目录不是一个tree或blob记录，而是一个特殊的160000的commit,这个commit不存在于总仓库下（.git/subject）里没有，这存在于其对应的真实仓库（.gitmodules记录）的commit,所以总仓库版本控制子模块并不直接控制其文件，而是其仓库的commit

git 针对工作区才能用的命令（裸仓库不能用）：
git status
git add 
git submodule init
针对仓库的命令：
git log


go build: 将丢弃除了最后的可执行文件之外所有的中间编译结果
go install: 将保留每个包的编译成果：$GOPATH/pkg/../*.a, 这些成果当对应的包没有发生变化，go build 和go install 都不会重新编译这些包，而是直接用这些，go build 可以用 go build -i 强制重新编译依赖(go build 也会去用.a,但他本身不会保留.a)


go特殊注释：
1.
import "C" 以上的行, 都有意义，且作为C语句： 如
// #include 
// #include 
// ..
import "C"

2. 放在文件第一行
// +build ignore
不编译这个文件
// +build linux darwin
针对不同平台和处理器类型使用不同代码

官方（推荐）：
放在$GOPATH/src下，作为非本地包
优点： 可以使用go install, go get等go工具
缺点： 比较不灵活，有些东西必须要个按照golang的规定，如不能引用本地包(即import使用相对路径, 提示错误：local import "./xx" in non-local package ，在这个路径下，所有包都视为非本地包），项目自用包(非网上的包, 即作为项目的一份，而不是从网上去clone，从而保证版本稳定等优点)必须在vendor下, 项目必须放在$GOPATH/src/xx下，等

作为本地包：放在非$GOPATH/src/{projectName}下
优点： 比较灵活，项目放哪都可以（不一定要在$GOPATH/src/{projectName}下），import可以使用相对路径，自己管理自用包的位置
缺点： 无法享受go install, go get 等工具，无法使用go install，因为go install项目必须严格在$GOPATH的src下，这也就无法享受go install工具带来的好处（如相对go build,go install保留了引用包的编译链接库.a文件，go install 会放到$GOPATH/pkg下，以后编译相应的包不发生变化不重新编译，提高了编译速度）, go get也无法很好的享用，go get会递归git clone 到$GOPATH/src下，并运行go install 


go工程结构： 同一代码以上方案只能取其一而不能共用(主要是相对路径包和vendor的互相不兼容)，如用了在第二种方案中用了相对路径的import，项目放到$GOPATH下则build不能够通过, 如在第一种方案中用了vendor的方案，则一旦离开官方项目目录结构，作为本地包，build的时候也不会去寻找vendor目录下的包

golang :
string 转[]byte： []byte(..) 将强转的[]byte赋值给变量是传值，因此新的切片变量底层引用的数组不是原来的string引用的byte数组
byte切片转string： string([]byte) 也是新的
byte数组不能直接转string， 如 var a [5]byte; string(a)
可以先转切片，数组转切片好转，只需 a[:5] , 所以 string(a[:5])


变量存储在内存中的字节对齐：
原因：
目前计算机内存按照字节编址，每个地址的内存大小为1个字节。而读取数据的大小和数据线有关。比如数据线为8位那么一次读取一个字节，而如果数据线为32位，那么一次需要读取32个字节，这样是为了一次更多的获取数据提高效率。否则读取一个int变量就需要进行4次内存操作。对于内存访问一般有以下两个条件：

    CPU进行一次内存访问读取的数据和字长相同。
    有些CPU只能对字长倍数的内存地址进行访问。

前端总线的宽度决定了cpu一次能读的数据的长度,在32位的操作系统下(cpu决定了一次最多能读多少,具体一次最多读多少还要看操作系统，若64为cpu上使用32位操作系统，那么依旧只能发挥32位作用，一次读取4字节）,一次是读4个字节的,而且每次读数据时的内存起始地址必须为4的倍数

1. S3C2400类ARM CPU，你在32位模式下访问不是4字节对齐的int数据，直接会产生一个异常。如果OS、固件等没有做特殊处理就会调用缺省的异常处理，一般来说就是抛出些信息从而死机。有些OS，对这个异常做了处理，帮你在4字节对齐的位置上读了两次，然后拼凑好结果交给你。你似乎觉得没有发生什么事情。这样做性能很不好，异常等over head太大，所以小的嵌入式系统都不会照此办理。但写一般的程序也不必担心，编译器会帮你对齐（除非你自己指定地址）；如果是访问不是4对齐的单个字节，则CPU还是会取出4对齐的4字节，只是把你需要的那个字节存到你的目标寄存器里罢了，譬如你问题里的地址3，就会把前面4个字节全读出来，把3的值放到你的目标寄存器中。2. X86 CPU，读int不对齐，硬件会做两次操作帮你拼好。不会产生异常但也效能不好，所以编译器也会做对齐优化。

静态类型语言是指在'编译时'变量的数据类型即可确定的语言
动态类型语言是在'运行时'确定数据类型的语言


golang:
type foo struct{
..
}

reflect.TypeOf(new(foo)) => *foo
reflect.TypeOf(foo{}) => foo

.git/index存放的是暂存区的快照（一个类似tree对象的)

git submodule 对go get 有效

只能给本地类型定义方法，即不能给一个导入包的导出类型在包外为他添加一个方法,只能在他包内

log与fmt: log多了日期时间
log.Println("hello"):
2018/03/15 10:31:43 hello
fmt.Println("hello"):
hello

http
req:
GET /dnakit/wangrongda HTTP/1.1\r\nUser-Agent: chrome\r\nAccept: application/json, text/plain\r\n\r\nbody
res:
HTTP/1.1 432 Not Found\r\nContent-Length: 19a\r\n\r\nbody

码点表示字符
"世界"
"\u4e16"和 '\u4e16' 都表示 ‘世’，
但他们的二进制数据都不一样，前者占用3字节，而后者占用4字节
后者是unicode(固定长rune)， 前者是经过UTF-8编码

只能用16进制表示
\x 表示8bit码点，两个16进制
\u 表示16bit码点, 4个16进制
\U 表示32bit码点, 8个16进制

字面量
二进制： 无
八进制字面量： 数字0开头
十六进制字面量： 0x开头

len(string)取的是字符串的byte数： len("hello王") => 8 (王被编码为utf8占三个字节)
要取字符串的字符个数：
1. utf8.RuneCountInString("hello王") => 6 (import "unicode/utf8")
2. len([]rune("hello王")) => 6

HTTP/1.1:
首先, 来说说什么是Content-Length,在http的协议中Content-Length首部告诉浏览器报文中实体主体的大小。这个大小是包含了内容编码的，比如对文件进行了gzip压缩，Content-Length就是压缩后的大小（这点对我们编写服务器非常重要）。除非使用了分块编码，否则Content-Length首部就是带有实体主体的报文必须使用的。使用Content-Length首部是为了能够检测出服务器崩溃而导致的报文截尾，并对共享持久连接的多个报文进行正确分段.

相应数据包协议头Content-Length指定大小x(B) > body实际大小： 正常(body为空时会出错，body为空必须content-length: 0)
                                           < body实际大小： 解析出错


golang: 顺序不能倒，Header().Set()必须在WriteHeader前，否则无效; WriteHeader必须在Write()前, 因为发送请求体前必须把报头信息放在前面,否则后面设置的header无效，发送的header为默认的（如content-length根据发送的主体算出等等，由http包处理）
w.Header().Set("Content-Length", "5")
w.WriteHeader(200)
w.Write()

golang:
json字节序反序列化：
 json.Unmarshal([]byte, 可以是结构体或map[string]string)


gorm: 
匿名结构体会直接嵌入作为表字段
非嵌入则关联另一张表 1对1
类型为数组： 1对多或多对多
type Dog struct {
//	ID uint `gorm:"primary_key;AUTO_INCREMENT"`
	Color3 string
	Leg3 int
}
type Cat struct {
	UserMm uint
	ID uint `gorm:"primary_key;AUTO_INCREMENT"`
	Color string
	Leg int
}

type User struct {
	ID  uint `gorm:"primary_key;AUTO_INCREMENT"`
	Age int `gorm:"-"`
	Name string `gorm:"size:225;"`
//	Cat Cat
	Dog
	Cats []Cat `gorm:"foreignkey:user_mm"`
}

n2n的各edge之间传输数据

是否走 s-node

完全取决于，两个 edge 节点所在的网络环境

1、如果是公网IP，则点对点传输数据，无需s-node介入

2、如果两端的路由器都是圆锥形NAT，注意「都是」圆锥形的NAT的话，两者之间可以直接传输数据，无需s-node介入

3、有一方面的设备在一个对称型的路由器后面，则无法完成点对点的直接传输，流量都需要superNode的中转。

./supernode -f -v -l 8899


wild notion:
1. 不同于UTF-8的编码方式：
使用字节最后一位为标志，如0为字符结束，1为还没结束。

printf: 格式化输出到[[标准输出]]
scanf: 从[[标准输入]]中格式化获取值到变量

fprintf: 格式化输出到[[fd]]
fscanf: 从[[fd]]中格式化获取值到变量

sprintf: 格式化输出到[[字符串]]
sscanf: 从[[字符串]]格式化读取值到变量

git update-index --assume-unchanged

mysql从第几条到第几条: (第一个数为第几条（从0开始）， 第二个为查几条）
 select * from table limit 0, n; //前n条
select * from table limit m, n; // 第m+1条到第m+n 

URL中要表示字符'/'需转义：%2f，如果%2f依旧会被转回分隔符/，则将'%'也编码


备份:
tar --exclude='/home/d/ubuntu' -vcf - /etc /home /var /usr/local/bin   | xz -9 -T0 -c - > backup.tar.xz

JS资源的请求和执行顺序：
<html> ...
<script src="url1"></script>
<script src="url2"></script>
...
</html>

如上 url1和url2会异步请求（同时），url2可能会比url1先响应，但是执行是同步的，url2的js拿到了也要等url1的js执行完（两种情况：url1成功响应并执行，2. url1响应失败）才会执行url2的脚本
url1执行出错(如某条语句错了，不往下执行url1），不影响url2的执行(独立的，但是在同一个js主线程，有共同的作用域，异步队列）。
