--
\n is linefeed, Ctrl-j or character 012
\r is carriage retrun, Ctrl-M or character 015
--

git:
gitignore ignore untracked file only when tracking to add
已经跟踪的文件不会忽略

.gitignore: 支持通配符
test:
	./test
	./xx/test
	./test/xx
	./xx/test/
/test:
	./test
	./test/xx
test/:
	./test/xx
	./xx/test/
/test/:
	./test/xx

doc/*.pdf:
	./doc/a.pdf
	./doc/b.pdf
doc/*/*.pdf:
	./doc/xx/a.pdf
	./doc/xx/b.pdf
doc/**/*.pdf:
	./doc/a.pdf
	./doc/b.pdf
	./doc/xx/a.pdf
	./doc/xx/b.pdf

git diff --cached/staged: stage(commited)和版本库比较
git diff: working tree(unstaged)和 stage比较,若stage里没有则和版本库比较, 即只要工作区发生改变的,就会有，stage有和stage比较，stage没有和respo比较

git commit -a: 会包括delete

git rm: 会untrack并删除工作区,相当于直接删除工作区文件并git add
git mv: 相当于直接mv文件系统并git add
git rm --cache: 只是untrack文件
git rm \*~: 通配符需要转义，不用bash的

git commit --amend: 一个全新的快照添加并覆盖原来的，原来的被从历史里删除（sha-1摘要变化了), 尽管不再历史里，还是有办法恢复到这个提交（git数据恢复篇)

git checkout file: 清除工作区修改(未add到暂存区的快照叫工作区），比较危险，除非是非常确定的情况下，否则拉个分支再清除比较安全

alpha: 内部版本
beta: 测试版
rc: 即将作为正式版发布
lts: 长期维护

git add: stage快照中对于修改过的文件copy了一份
git commit: 快照直接指向stage,对象里包括这个指针、author's name and email, commit message ...

.git/object：对象库，存放所有对象：文件（该目录最大的原因）（不只是工作目录的文件，只要曾经被add的文件都会被存放，stage快照中修改过的文件被存为新的，未修改被add的直接引用，,,所以包括被修改过的副本，被删除的也会被保留，!!!!只要曾经被add的，校验和不存在的，就会被添加!!!!。 以sha-1校验和区分）; 文件树，存放快照文件结构,包含的指向若干文件对象等; 提交对象，包括tree指针指向前面那个树的校验和，parent指针指向该分支上一个提交对象的校验和,username, email等
tip: 文件被编译为二进制，使用git cat-file <checksum>查看

git checkout -- file: 丢弃工作区的修改，将modified的文件的修改复原（可能复原到和staged的一样，或和版本库一样)
一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；
一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。
总之，就是让这个文件回到最近一次git commit或git add时的状态。

./git/object里不包括staged的快照（tree对象）,stage的信息(目录结构快照)保存在.git/index
使用git ls-files --stage(index文件被编译为二进制文件)查看：
100644 95ef7c6bd1c2d0a7ac268241dd4bd4b1415da423 0       .gitignore
100644 f4bc36652eee71c7e127a40b68137235a2aeb6e4 0       go1.9.2.linux-amd64.tar.gz
100644 529ba277c064f3d312a647eb5247d1ca3421eb6e 0       main.c

当commit后会生成commit的对象和tree对象(文件名为校验和，tree的文件内容如下） 在object目录下，tree对象就是由上面的index得来：
tree对象: 
100644 blob 95ef7c6bd1c2d0a7ac268241dd4bd4b1415da423    .gitignore
100644 blob f4bc36652eee71c7e127a40b68137235a2aeb6e4    go1.9.2.linux-amd64.tar.gz
100644 blob 529ba277c064f3d312a647eb5247d1ca3421eb6e    main.c


linux: ls -lh 
第2个参数: 
1, 若为文件，表示硬链接数
2, 若为目录，表示有多少个子目录（包括.和..，所以至少2, 同时包括隐藏）


git pull origin next:master 取回主机的next分支与本地的master分支合并，省略则与当前分支合并

git push -u origin master: 关联远程（上游）

git push origin <本地分支>:<远程分支>: 远程分支省略则推送到与本地分支对应的上游分支通常为<远程名>/<本地分支名>（本地跟踪远程的分支）, 如果该远程分支不存在，则会被新建（和本地分支同名）
若本地分支为空 git push origin :<远程分支> 则删除远程分支  == git push origin --delete <master>

git push origin 将当前分支推到origin主机对应的分支

go: 一个目录只能有一个包若发现两个包（如同一个目录有两个文件分别为package a, package b)，编译不会通过
一个目录的go文件的包名一般和目录名一样（可以不一样，import的时候import目录，包名还是go文件的包名,容易引起混乱)

go install github.com/test: (或者cd $GOPATH/src/github.com/test && go install)
1. 将$GOPATH/src/github.com/test的源文件进行编译，包编译成.a放到相应的$GOPATH/pkg/github.com/test下，main包编译成可执行文件到bin/test(没有github.com/test)下
go get github.com/test: (会递归clone依赖） go get -u 确保所有包和依赖包都是最新的，然后重新编译安装他们
1. git clone https://github.com/test $GOPATH/github.com/test
2. git install github.com/test



foo := []rune //slice
foo := [3]rune //array
foo := [...]rune //array

unsafe.sizeof([]rune) // 24 ( len(8) + cap(8) + data(8, a point to real array) )
unsafe.sizeof([3]rune) // 12 ( 3 x 4(int32) )

slice = append(slice, element) // 给slice追加一个元素（len加1）， 若cap足够，则直接在原底层数组上, cap不变; 若cap不够，则另外申请一个底层数组（cap可能是原来的两倍或其他策略），将之前的元素copy到新数组，并追加，cap改变; 无论是哪一种，都会将返回 ‘新的’ slice, 就的不变， 通常需要将‘新的’赋给原slice

string: 不可改变的字节序列（只读[]byte）， UTF8编码


字面量：
十进制： 123
八进制： 0327(第一位: 阿拉伯数字 零)
十六进制： 0x32af 

fmt.Printf("
1) %b ：二进制(不会根据变量占有内存在前面补0变成固定长度)
2) %d :	十进制
3) %x : 


golang not allow : 
1) 连等
2) 三元运算符 ?



js: 
0 == "" // true 
0 == "0" //true
0 == "1" //false
0 == [] //true
0 == [0] //true
if ("")  // if (false)
if ([]) // if (true)


快的程序往往是伴随着较少的内存分配


查看某命令（文件）属于哪个包：
pacman -Qo file
查看某软件包的文件信息：
pacman -Ql package
软件包的其他信息：
pacman -Qi package

查看可执行文件依赖的共享库(以gtk/qt为例)：
ldd $(which evince) | grep 'gtk\|qt'
查看进程的调用的动态共享库so：
pmap -p $pid | grep 'gtk|Qt'


test中使用全局是安全的, go test命令并不会同时并发地执行多个测试

生成目标代码（不链接生成可执行）： gcc -c demo.c => demo.o
生成静态链接库: ar rv libx.a x1.o x2.o ..
生成共享库： gcc -shared -o libx.so x1.o x2.o (通常-fPIC)

链接（共享/静）库： gcc -lx main.o -o exe (同时存在libx.a, libx.so,优先so, 默认库gcc_s等以动态形式链接)
强制全部静态链接： gcc -static -lx main.o -o exe (需要libx.a, 包括了动态连接时（不指明static时）的ld.so, gcc_s 等默认共享库都会被静态链接，所以出来的可执行文件较大,完全独立）
部分强制静态链接： gcc -Wl,Bstatic -lx ( 需要带上-Wl,Bdynamic -lgcc_s，否则编译不通过，且这种方法一般没有gcc_s的静态库, 要静态链接这一部分占时用全部静态-static）
动态部分： gcc -Wl,Bdynamic -lx (这会导致-static失效）

静态链接库： .a, 在链接成可执行文件时，静态链接库被链接进程序且运行不再依赖与这个.a
共享库(动态链接）: .so , 链接成可执行文件时指明依赖的共享库，共享库的内容不会被写进程序，运行可执行文件时需要依赖共享库so, 并且在程序启动时就加载(在指明依赖链接库时优先使用共享库，除非强制指明静态链接)
动态加载共享库：void*dlopen (const char *libname, int flag); 不像动态链接的共享库，程序启动时就被ld.so寻找并装载，而是需要的时候由程序函数调用的共享库so

//如果要链接没有lib前缀的库文件，可以直接指定库的全名，无需加-L，-l选项
//另外，当编译可执行文件需要链接多个静态库的情况：
1、静态库是前后依赖关系，则依赖库靠前，被依赖的库靠后，如a依赖b，-la -lb
2、静态库是相互依赖关系，则需要多次添加同一个库，如a依赖b，同时b依赖a，-la -lb -la
3、有没有比较优雅的方式解决第2种情况，有，加链接的属性，如：-Xlinker --start-group -la -lb -Xlinker --end-group

C:
动态库装载：
共享库的寻找和加载是由/lib/ld.so /lib/ld-linux.so实现的，ld.so在标准路径/lib, /usr/lib中寻找应用程序用到的共享库(用到非标准库中库的做法是将非标准库路径加入/etc/ld.so.conf,然后运行ldconfig生成/etc/ld.so.cache。ld.so加载共享库时，会从ld.so.cache查找。ld加载共享库的时候，也会差好LD_LIBRARY_PATH这个环境变量)


ldd(不是一个可执行程序，是一个shell脚本): 打印一个执行程序的 共享库依赖关系。
这个脚本通过设置一系列环境变量:
"LD_TRACE_LOADED_OBJECTS、LD_WARN、LD_BIND_NOW、LD_LIBRARY_VERSION、LD_VERBOSE等。
当LD_TRACE_LOADED_OBJECTS环境变量不为空时，任何可执行程序在运行时，它都会只显示模块的 dependency，而程序并不真正执行"
如 export LD_TRACE_LOADED_OBJECTS=1; ls; 将只显示ls执行程序的依赖共享库。而不执行ls
原理：
通过ld-linux.so动态库装载器实现的,ld-linux.so模块会优先与executable模块程序工作，并获得控制权，因此上述环境变量被设置时，ld-linux.so选择显示可执行模块的依赖
实际上可以直接执行ld-linux.so模块： /lib/ld-linux.so --list program  = ldd program

那程序又是怎么找到ld-linux.so的： ld-linux.so的位置是写死在程序中的，gcc在编译程序时就写死在里面了。gcc写到程序中ld-linux.so的位置是可以改变的，通过修改gcc的spec文件

运行时，ld-linux.so查找共享库的顺序
（1）ld-linux.so.6在可执行的目标文件中被指定，可用readelf命令查看 
（2）ld-linux.so.6缺省在/usr/lib和lib中搜索；当glibc安装到/usr/local下时，它查找/usr/local/lib
（3）LD_LIBRARY_PATH环境变量中所设定的路径 
（4）/etc/ld.so.conf（或/usr/local/etc/ld.so.conf）中所指定的路径，由ldconfig生成二进制的ld.so.cache中

编译时，ld-linux.so查找共享库的顺序
（1）ld-linux.so.6由gcc的spec文件中所设定 
（2）gcc --print-search-dirs所打印出的路径，主要是libgcc_s.so等库。可以通过GCC_EXEC_PREFIX来设定 
（3）LIBRARY_PATH环境变量中所设定的路径，或编译的命令行中指定的-L/usr/local/lib 
（4）binutils中的ld所设定的缺省搜索路径顺序，编译binutils时指定。（可以通过“ld --verbose | grep SEARCH”来查看） 
（5）二进制程序的搜索路径顺序为PATH环境变量中所设定。一般/usr/local/bin高于/usr/bin
（6）编译时的头文件的搜索路径顺序，与library的查找顺序类似。一般/usr/local/include高于/usr/include


=====================================================================
gcc 编译的四大过程（预处理-编译-汇编-链接 ）

     我们来编译一个hello world 程序。

#include <stdio.h>

int main(int argc,const char* argv[])

{

    printf("hello world!\n");

    return 0;

}
1）预处理(Pre-processing)
在该阶段，编译器将C源代码中的包含的头文件如stdio.h编译进来，用户可以使用gcc的选项”-E”进行查看。
用法:#gcc -E main.c -o main.i
作用：将main.c预处理输出main.i文件

[user:test] ls
main.c
[user:test] gcc -E main.c -o main.i
[user:test] ls
main.c  main.i

 

2)编译阶段(Compiling)
第二步进行的是编译阶段，在这个阶段中，Gcc首先要检查代码的规范性、是否有语法错误等，以确定代码的实际要做的工作，在检查无误后，Gcc把代码翻译成汇编语言。用户可以使用”-S”选项来进行查看，该选项只进行编译而不进行汇编，生成汇编代码。
选项 -S
用法：[user]# gcc –S main.i –o main.s
作用：将预处理输出文件main.i汇编成main.s文件。

[user:test] ls
main.c  main.i
[user:test] gcc -S main.i -o main.s
[user:test] ls
main.c  main.i  main.s

3)汇编阶段(Assembling)
汇编阶段是把编译阶段生成的”.s”文件转成二进制目标代码.
选项 -c
用法：[user]# gcc –c main.s –o main.o
作用：将汇编输出文件main.s编译输出main.o文件。

[user:test] ls
main.c  main.i  main.s
[user:test] gcc -c main.s -o main.o
[user:test] ls
main.c  main.i  main.o  main.s

4）链接阶段(Link)
在成功编译之后，就进入了链接阶段。
无选项链接
用法：[user]# gcc main.o –o main.exe
作用：将编译输出文件main.o链接成最终可执行文件main.elf

[user:test] ls
main.c  main.i  main.o  main.s
[user:test] gcc main.o -o main.elf
[user:test] ls
main.c  main.elf*  main.i  main.o  main.s
=======================================================================

go build/install: 当前目录为项目目录
go build/install [pack]: $GOPATH/src/pack为项目目录

golang 项目自己的依赖包（不从互联网上get)
放在项目下的vendor目录
即使使用vendor，也必须在GOPATH中，在go的工具链中，你逃不掉GOPATH的

那么查找依赖包路径的解决方案如下：
    当前项目目录（先检查是否在$GOPATH/src/projec, 也是下面一条的前提)下的vendor目录。
    向上级目录查找，直到找到src下的vendor目录。
    在GOPATH下面查找依赖包。
    在GOROOT目录下查找

在使用vendor中，给出如下建议：

    一个库工程（不包含main的package）不应该在自己的版本控制中存储外部的包在vendor\目录中，除非他们有特殊原因并且知道为什么要这么做。
    在一个应用中，（包含main的package），建议只有一个vendor目录在代码库一级目录。

上面建议的原因如下：

    在目录结构中的每个包的实例，即使是同一个包的同一个版本，都会打到最终的二进制文件中，如果每个人都单独的存储自己的依赖包，会迅速导致生成文件的二进制爆发（binary bloat)
    在一个目录的某个pacage类型，并不兼容在同一个package但是在不同目录的类型，即便是同一个版本的package，那意味着loggers，数据库连接，和其他共享的实例都没法工作。


git 中某git仓库的工作目录下的子目录不能够有自己的git仓库，当一个子目录下有自己的git仓库，则该子目录工作区的所有文件和版本库不会被总版本库添加，若子目录需要有自己的版本控制，则通过子模块,为其添加子模块，总版本库通过.gitmodules知道哪些目录是子版本库，里面记录了子版本库目录以及对应的真实(远程)仓库url,总仓库不包含子模块的任何版本信息（文件，仓库等），当clone一个包含子模块的仓库时，会发现子模块所在目录是空的（工作区，.git仓库, git文件), 只有总工作区有一个.gitmodule文件被保留，需要执行git submodule init(会根据.gitmodules文件将url注册到目录）， git submodule update(这一步会在子目录创建工作区文件和.git文件，git文件记录真实的git的仓库地址，通常在总仓库目录下: .git/modules/相应的目录地址 , 总仓库下的modules目录用于存放所有其他子模块的本地仓库，统一管理（不单独放在他们工作区下）,这个modules目录也是git submodule update时创建的。
.gitmodules文件的url若使用的是相对地址，则是相对总仓库的url，如别人clone这个总仓库时，那么就以clone的url为域名（有趣的是你这么干,子仓库真的存在于子目录下，而子目录任何东西不会被提交，当你push到远程，远程就再也拿不到这个仓库，或者当别人pull你，这个子模块的仓库会作为远程在.git/modules下，结构也不一样，反正种种问题，不建议使用相对地址子模块或者将一个仓库放在另一个仓库的子目录下）

git 子模块：
git submodule add [git地址] [到目录]
会添加远程仓库到但前目录下指定的位置
子模块git仓库不放在自己的仓库目录下，可以ls .git/ 没有这个目录，而有.git这个文件，这个文件指明了实际仓库的位置，cat .git可以看到仓库被放到了父模块的.git总仓库下的modules目录 下。
同时在总仓库下生成一个.gitmodule文件，记录各个子模块项目路径了上游url,只有存在这个文件，git才能知道谁是子模块

git diff: 工作区和stage比或和仓库比
git diff --cached: stage和仓库比


一个可能的包含子模块的tree快照
git cat-file -p 55493783344510bdffa0c63bcedd3a054ac652df
100644 blob 11ae4f2eef95dfe9219cee0d97cb6f372e349be4    .gitmodules
100644 blob 4d51fa4e2aba7d68840dcdb059eca7a1719b8fed    candy.go
100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391    main.go
160000 commit 392d907deb6503fdba6d81a8318662a8e6c36f8e  subcandy

可以看到对于这个目录不是一个tree或blob记录，而是一个特殊的160000的commit,这个commit不存在于总仓库下（.git/subject）里没有，这存在于其对应的真实仓库（.gitmodules记录）的commit,所以总仓库版本控制子模块并不直接控制其文件，而是其仓库的commit

git 针对工作区才能用的命令（裸仓库不能用）：
git status
git add 
git submodule init
针对仓库的命令：
git log


go build: 将丢弃除了最后的可执行文件之外所有的中间编译结果
go install: 将保留每个包的编译成果：$GOPATH/pkg/../*.a, 这些成果当对应的包没有发生变化，go build 和go install 都不会重新编译这些包，而是直接用这些，go build 可以用 go build -i 强制重新编译依赖(go build 也会去用.a,但他本身不会保留.a)


go特殊注释：
1.
import "C" 以上的行, 都有意义，且作为C语句： 如
// #include 
// #include 
// ..
import "C"

2. 放在文件第一行
// +build ignore
不编译这个文件
// +build linux darwin
针对不同平台和处理器类型使用不同代码

官方（推荐）：
放在$GOPATH/src下，作为非本地包
优点： 可以使用go install, go get等go工具
缺点： 比较不灵活，有些东西必须要个按照golang的规定，如不能引用本地包(即import使用相对路径, 提示错误：local import "./xx" in non-local package ，在这个路径下，所有包都视为非本地包），项目自用包(非网上的包, 即作为项目的一份，而不是从网上去clone，从而保证版本稳定等优点)必须在vendor下, 项目必须放在$GOPATH/src/xx下，等

作为本地包：放在非$GOPATH/src/{projectName}下
优点： 比较灵活，项目放哪都可以（不一定要在$GOPATH/src/{projectName}下），import可以使用相对路径，自己管理自用包的位置
缺点： 无法享受go install, go get 等工具，无法使用go install，因为go install项目必须严格在$GOPATH的src下，这也就无法享受go install工具带来的好处（如相对go build,go install保留了引用包的编译链接库.a文件，go install 会放到$GOPATH/pkg下，以后编译相应的包不发生变化不重新编译，提高了编译速度）, go get也无法很好的享用，go get会递归git clone 到$GOPATH/src下，并运行go install 


go工程结构： 同一代码以上方案只能取其一而不能共用(主要是相对路径包和vendor的互相不兼容)，如用了在第二种方案中用了相对路径的import，项目放到$GOPATH下则build不能够通过, 如在第一种方案中用了vendor的方案，则一旦离开官方项目目录结构，作为本地包，build的时候也不会去寻找vendor目录下的包

golang :
string 转[]byte： []byte(..) 将强转的[]byte赋值给变量是传值，因此新的切片变量底层引用的数组不是原来的string引用的byte数组
byte切片转string： string([]byte) 也是新的
byte数组不能直接转string， 如 var a [5]byte; string(a)
可以先转切片，数组转切片好转，只需 a[:5] , 所以 string(a[:5])


变量存储在内存中的字节对齐：
原因：
目前计算机内存按照字节编址，每个地址的内存大小为1个字节。而读取数据的大小和数据线有关。比如数据线为8位那么一次读取一个字节，而如果数据线为32位，那么一次需要读取32个字节，这样是为了一次更多的获取数据提高效率。否则读取一个int变量就需要进行4次内存操作。对于内存访问一般有以下两个条件：

    CPU进行一次内存访问读取的数据和字长相同。
    有些CPU只能对字长倍数的内存地址进行访问。

前端总线的宽度决定了cpu一次能读的数据的长度,在32位的操作系统下(cpu决定了一次最多能读多少,具体一次最多读多少还要看操作系统，若64为cpu上使用32位操作系统，那么依旧只能发挥32位作用，一次读取4字节）,一次是读4个字节的,而且每次读数据时的内存起始地址必须为4的倍数

1. S3C2400类ARM CPU，你在32位模式下访问不是4字节对齐的int数据，直接会产生一个异常。如果OS、固件等没有做特殊处理就会调用缺省的异常处理，一般来说就是抛出些信息从而死机。有些OS，对这个异常做了处理，帮你在4字节对齐的位置上读了两次，然后拼凑好结果交给你。你似乎觉得没有发生什么事情。这样做性能很不好，异常等over head太大，所以小的嵌入式系统都不会照此办理。但写一般的程序也不必担心，编译器会帮你对齐（除非你自己指定地址）；如果是访问不是4对齐的单个字节，则CPU还是会取出4对齐的4字节，只是把你需要的那个字节存到你的目标寄存器里罢了，譬如你问题里的地址3，就会把前面4个字节全读出来，把3的值放到你的目标寄存器中。2. X86 CPU，读int不对齐，硬件会做两次操作帮你拼好。不会产生异常但也效能不好，所以编译器也会做对齐优化。

静态类型语言是指在'编译时'变量的数据类型即可确定的语言
动态类型语言是在'运行时'确定数据类型的语言


golang:
type foo struct{
..
}

reflect.TypeOf(new(foo)) => *foo
reflect.TypeOf(foo{}) => foo

.git/index存放的是暂存区的快照（一个类似tree对象的)

git submodule 对go get 有效

只能给本地类型定义方法，即不能给一个导入包的导出类型在包外为他添加一个方法,只能在他包内

log与fmt: log多了日期时间
log.Println("hello"):
2018/03/15 10:31:43 hello
fmt.Println("hello"):
hello

http
req:
GET /dnakit/wangrongda HTTP/1.1\r\nUser-Agent: chrome\r\nAccept: application/json, text/plain\r\n\r\nbody
res:
HTTP/1.1 432 Not Found\r\nContent-Length: 19a\r\n\r\nbody

码点表示字符
"世界"
"\u4e16"和 '\u4e16' 都表示 ‘世’，
但他们的二进制数据都不一样，前者占用3字节，而后者占用4字节
后者是unicode(固定长rune)， 前者是经过UTF-8编码

只能用16进制表示
\x 表示8bit码点，两个16进制
\u 表示16bit码点, 4个16进制
\U 表示32bit码点, 8个16进制

字面量
二进制： 无
八进制字面量： 数字0开头
十六进制字面量： 0x开头

len(string)取的是字符串的byte数： len("hello王") => 8 (王被编码为utf8占三个字节)
要取字符串的字符个数：
1. utf8.RuneCountInString("hello王") => 6 (import "unicode/utf8")
2. len([]rune("hello王")) => 6

HTTP/1.1:
首先, 来说说什么是Content-Length,在http的协议中Content-Length首部告诉浏览器报文中实体主体的大小。这个大小是包含了内容编码的，比如对文件进行了gzip压缩，Content-Length就是压缩后的大小（这点对我们编写服务器非常重要）。除非使用了分块编码，否则Content-Length首部就是带有实体主体的报文必须使用的。使用Content-Length首部是为了能够检测出服务器崩溃而导致的报文截尾，并对共享持久连接的多个报文进行正确分段.

相应数据包协议头Content-Length指定大小x(B) > body实际大小： 正常(body为空时会出错，body为空必须content-length: 0)
                                           < body实际大小： 解析出错


golang: 顺序不能倒，Header().Set()必须在WriteHeader前，否则无效; WriteHeader必须在Write()前, 因为发送请求体前必须把报头信息放在前面,否则后面设置的header无效，发送的header为默认的（如content-length根据发送的主体算出等等，由http包处理）
w.Header().Set("Content-Length", "5")
w.WriteHeader(200)
w.Write()

golang:
json字节序反序列化：
 json.Unmarshal([]byte, 可以是结构体或map[string]string)


gorm: 
匿名结构体会直接嵌入作为表字段
非嵌入则关联另一张表 1对1
类型为数组： 1对多或多对多
type Dog struct {
//	ID uint `gorm:"primary_key;AUTO_INCREMENT"`
	Color3 string
	Leg3 int
}
type Cat struct {
	UserMm uint
	ID uint `gorm:"primary_key;AUTO_INCREMENT"`
	Color string
	Leg int
}

type User struct {
	ID  uint `gorm:"primary_key;AUTO_INCREMENT"`
	Age int `gorm:"-"`
	Name string `gorm:"size:225;"`
//	Cat Cat
	Dog
	Cats []Cat `gorm:"foreignkey:user_mm"`
}

n2n的各edge之间传输数据

是否走 s-node

完全取决于，两个 edge 节点所在的网络环境

1、如果是公网IP，则点对点传输数据，无需s-node介入

2、如果两端的路由器都是圆锥形NAT，注意「都是」圆锥形的NAT的话，两者之间可以直接传输数据，无需s-node介入

3、有一方面的设备在一个对称型的路由器后面，则无法完成点对点的直接传输，流量都需要superNode的中转。

./supernode -f -v -l 8899


wild notion:
1. 不同于UTF-8的编码方式：
使用字节最后一位为标志，如0为字符结束，1为还没结束。

printf: 格式化输出到[[标准输出]]
scanf: 从[[标准输入]]中格式化获取值到变量

fprintf: 格式化输出到[[fd]]
fscanf: 从[[fd]]中格式化获取值到变量

sprintf: 格式化输出到[[字符串]]
sscanf: 从[[字符串]]格式化读取值到变量

git update-index --assume-unchanged

mysql从第几条到第几条: (第一个数为第几条（从0开始）， 第二个为查几条）
 select * from table limit 0, n; //前n条
select * from table limit m, n; // 第m+1条到第m+n 

URL中要表示字符'/'需转义：%2f，如果%2f依旧会被转回分隔符/，则将'%'也编码


备份:
tar --exclude='/home/d/ubuntu' -vcf - /etc /home /var /usr/local/bin   | xz -9 -T0 -c - > backup.tar.xz

JS资源的请求和执行顺序：
<html> ...
<script src="url1"></script>
<script src="url2"></script>
...
</html>

如上 url1和url2会异步请求（同时），url2可能会比url1先响应，但是执行是同步的，url2的js拿到了也要等url1的js执行完（两种情况：url1成功响应并执行，2. url1响应失败）才会执行url2的脚本
详细：
js主线程(空闲的)先异步请求url1资源，再异步请求url2资源，无论哪个资源先响应，url1脚本执行完再执行url2脚本.
但是当脚本执行的时候，不仅仅js主线程单线程，<script src>的请求也会停止：
<script src="url1"></script>
<script>
 sleep(3) //具有 同步阻塞3秒 功能的函数sleep()
</script>
<script src="url2"></script>
若url1响应时间比较长，则js主线程在获取到并执行url1之前空闲，继续异步请求url2资源，然后按顺序执行下来
若url1响应很快，赶在异步请求url2资源前，则会优先运行url1,然后阻塞3秒，然后才请求url2(运行url1和sleep(3)这段代码时，无法同时请求url2,只有js线程空闲时才行)


url1执行出错(如某条语句错了，不往下执行url1），不影响url2的执行(独立的（就像是在browser终端一次执行多条语句，为一块），但是在同一个js主线程，有共同的作用域，异步队列）。


setTimeout延时时间参数设为0, 表示直接放到异步队列（不会马上执行）
	延时时间设为100, 表示100ms后放到异步队列（并不是100ms后立即执行，js主线程单线程，也不会中断）


golang:
对于引用包里的东西，用"."引用的变量，方法等，凡是用"."符号引用的，都必须是大写的： 包名.(首字母大写)xxx.(首字母大写)xxx
package xx
type sub struct {
  A int
}
type Foo struct {
  sub
}

package main
import xx
func main() {
  var foo xx.Foo
  foo.A //可以, 尽管嵌套结构体的是小写sub, 但是只管"."号可以直接引用的名字是大写开头就好
  foo.sub.A //不可以
}


golang:
http package:
r.PostForm // map[string][]string：存放formdata的参数
r.URL.Query() // map[string][]string: 存放url的参数
r.Form // map[string][]string 存放url参数和formdata参数,合2为一
以上三个需要r.ParseForm(url)或r.ParseMultipartForm()(all)后才会存放到

r.ParseForm和ParseMultipartForm的区别:
r.ParseMultipartForm(maxMemory) //ParseMultiparForm要传一个参数，指定最大值使用内存， 调用这个函数会解析整个请求体（multipart/form-data格式），包括文件部分会存到内存，超出指定的maxMemory，文件剩下的部分存到磁盘缓存文件，如果请求体不是个multipart/form-data而是一个x-www-form-urlencode的话，会直接调用ParseForm(),
和ParseForm一样，也是先解析url参数

r.ParseForm() //先解析url参数，然后解析请求体(x-www-form-url)

r.FormValue(field) //从r.Form(内置r.ParseMultipartForm)里拿，没有的会返回空字符串，所以无法判断字段是 没有传还是传空值


golang通过反射设置结构体字段的值：
结构体字段必须是首字母大写，否则会出现：panic: reflect: reflect.Value.Set using value obtained using unexported field
在Golang中首字母的大小写代表着访问权限，首字母小写则包外无法访问

mv --backup=numbered 强制覆盖文件夹（旧的会备份为.~1~的文件夹)


import "packname"
若GOPATH下有两个packname, 会用第一个GOPATH里的


:= 只作用于局部变量(块作用域)，符号左边的被赋值的n个变量只会是局部变量（已存在的会用已存在的局部变量，不存在的会创建改局部变量，至少要有一个不存在）,也就是说不可能是全局变量或作用域以外（如闭包外）的变量，若左操作值有一个叫foo的变量, 且该作用域内没有foo的局部变量，全局有一个叫foo的全局变量，但他不会视为foo存在，仍会创建名为foo的局部变量。

接收多返回值的 变量，若想赋给全局变量或外面作用域的变量，记住只能用"="而不是":=", 否则同名局部变量会被创建
若其他变量里有未声明变量，只能通过提前声明。
如：
global: 
var foo string
----------------
func xx() {
   var err error //提前声明err
   foo, err = xxx //无法在这里使用 :=
}
==================================
example2:
func main() {
    var foo string
    if true {
       var err error
       foo, err = xxx //上面的foo
       foo, err := xxx //新的foo
    }
}


map的value类型为复合类型(如struct), 不能直接对struct的字段赋值，只能对这个key用整个新的struct赋值，
若要对字段赋值，只能将value的类型改为改复合类型的指针类型
type struct foo {
    Name string
}

bar := map[string]foo 
bar["hello"].Name = "world" //错误
====================================
bar := map[string]*foo
bar["hello"].Name = "world" //ok



defer 后面必须是一个可执行程序语句，如单条程序语句，若要多条，需要一个函数调用（不是函数名）或自执行匿名函数
1. defer fmt.Println("this is a defer")
2. defer func() {
    fmt.Println("This is a defer1")
    fmt.Println("This is a defer2")
}
3. defer test()
func test() {
    fmt.Println("This is a defer1")
    fmt.Println("This is a defer2")
}


当panic异常发生时，当前goroutine的当前函数会中断运行，并立即执行该函数中被延迟的函数（defer机制）, 若被panic被defer捕获（defer中调用了内置函数recover()), 出该函数到外层函数，外层函数正常运行，若panic没有被捕获，出该函数到外层函数，外层函数中断，并立即执行defer，一次循环, 直到线程主函数defer结束，panic还没有被捕获。进入底层defer会去调用runtime的堆栈信息括 panic value和函数调用的堆栈跟踪信息, 作为日志打出，到此程序中止（在这之前其他goroutine照常执行(除了从主函数退出或者直接终止程序之外，没有其它的编程方法能够让一个goroutine来打断另一个的执行),若其他gorroutine的panic比他快，则该goroutine会在defer过程中被中止也是有可能）。

defer的执行顺序，每经过一个defer，将该defer函数压如一个栈顶，等defer所在函数return时，依次从栈顶执行下来(该函数),直到defer不属于该函数（即外层函数）,外层函数继续执行，直到return...
panic 异常后会中断所在函数的继续执行，开始上面的defer栈执行, panic会传递到每一个执行过的defer，每一个经过的defer都可以捕获，若某个defer没有捕获，则继续执行下一个defer，若被某个defer捕获，则到下一个函数作用域，恢复程序流（不捕获的话，到下一个函数作用域，同样中断，直接执行defer)

KB = 10^3B = 1000B
KiB = 2^10B = 1024B

K,M,G,T,P,E,Z,Y (B/iB)

iota 在批量const里，每过一行自增1（从0开始），无论有没有出现iota
const (
    _ = 0 //iota = 0
    _ = 5 //iota = 1
    test = iota // test = iota = 2
    test2 //test2 = iota = 3, 因为批量const的特性，未赋值的常量值等于上一个常量（第一个不能不赋值），所以test2 = iota = 3
    test3 //test3 = iota = 4
)


json库对匿名结构体内嵌的处理：

没有json tag: 平铺
type foo struct {
	Address string
	bar  //或Bar都可以
}

type bar struct {
	Name string
	Age  int
}
json.Marshl(foo) => {"Address":"room404","Name":"wangrd","Age":23}

有json tag: 作为字段
type foo struct {
	Address string
	bar  `json:"bar"`
}

type bar struct {
	Name string
	Age  int
}
{"Address":"room404","bar":{"Name":"wangrd","Age":23}}


当一个golang程序启动时，其主函数在一个单独的goroutine中运行，叫它"main goroutine",新的goroutine会用go语句来创建
f()    // call f(); wait for it to return
go f() // create a new goroutine that calls f(); don't wait


主函数返回时，所有的goroutine都会被直接打断，程序退出。除了从主函数退出或者直接终止程序之外，没有其它的编程方法能够让一个goroutine来打断另一个的执行


Channel篇：

当通过一个无缓存Channels发送数据时，接收者收到数据发生在唤醒发送者goroutine之前

"并发"这并不是意味着x事件和y事件就一定是同时发生的，我们只是不能确定这两个事件发生的先后顺序。

当一个 channel 被关闭后，再向该 channel 发送数据将导致 panic 异常; 
当一个被关闭的 channel 中已经发送的数据都被成功接收后，后续的接收操作将不再阻塞，它们会立即返回一个零值 。
单向channels中，因为关闭操作只用于断言不再向 channel 发送新的数据，所以只有在发送者所在的 goroutine 才会调用 close 函数，因此对一个只接收的 channel 调用close 将是一个编译错误。

单向channels: 类型 chan<- int 表示一个只发送 int 的 channel，只能发送不能接收。相反，类型 <-chan int 表示一个只接收 int 的channel ，只能接收不能发送。这种限制将在编译期检查

不管一个 channel 是否被关闭 ，当它没有被引用时将会被Go语言的垃圾自动回收器回收。（不要将关闭一个打开文件的操作和关闭一个 channel 操作混淆。 对于每个打开的文件，都需要在不使用的使用调用对应的Close方法来关闭文件。）


一个基于无缓存 Channels 的发送操作将导致发送者 goroutine 阻塞，直到另一个 goroutine 在相同的 Channels 上执行接收操作，当发送的值通过 Channels 成功传输之后，两个 goroutine 可以继续执行后面的语句。反之，如果接收操作先发生，那么接收者 goroutine 也将阻塞，直到有另一个goroutine在相同的 Channels 上执行发送操作

所以在只有1个main goroutine的程序里在main里使用同步channel(无缓存)没有意义，程序会崩溃, 主协程被阻塞(等接收或等发送)且不可能恢复（没有人接收或没有人发送）,发生死锁

基于无缓存 Channels(又叫同步Channels) 的发送和接收操作将导致两个 goroutine 做一次同步操作
当通过一个无缓存 Channels 发送数据时 ，接收者收到数据发生在唤醒发送者 goroutine 之前

重复关闭一个 channel 将导致 panic 异常，关闭一个 nil 值的 channel 也将导致 panic 异常。关闭一个 channels 还会触发一个广播机制


goroutine与线程的区别: 
1. 动态栈
每一个OS线程都有一个固定大小的内存块(一般会是2MB)来做栈 
一个 goroutine 会以一个很小的栈开始其生命周期，一般只需要2KB，最大1G
2. 调度（切换） /重点: goroutine的调度开销远远小于线程调度开销
线程由操作系统 内核 调度，每几毫秒一个硬件计时器会中断处理器，goroutine有自己的调度器（用户空间下的线程，用户态的多线程），不是由硬件时钟来定期触发的，所以他不需要切换内核语境(不需要进入内核上下文)，协程通常是纯软件实现的多任务(用户空间调度器),与CPU和操作系统通常没有关系
3. goroutine没有一个特定的标识。





以前进程既是资源分配也是调度的最小单位,后来为了更合理的使用cpu(实际上是cpu性能越来越好),才将资源分配和调度分开,就有了线程,线程是cpu调度的最小单位,是程序执行流的最小单元。一个进程至少包含一个主线程


runtime.GOMAXPROCS(runtime.NumCPU())
GO默认的值是运行机器上的CPU的核心数，所以在一个有8个核心的机器上时，调度器一次会在8个OS线程上去调度GO代码
那么在多核环境下，什么情况下设置runtime.GOMAXPROCS会比较好的提高速度呢？
适合于CPU密集型、并行度比较高的情景。如果是IO密集型，CPU之间的切换也会带来性能的损失。


多线程运算的性能取决于核心数，计算速度取决于cpu主频等，当线程数和核心数相当时可以充分利用核心数, 多核心用于并行计算, 而线程是cpu调度的最小单位，一个线程一段时间内只能被一个核cpu调度执行，一个核cpu一段时间只能运行一段线程（并发），所以多核对单线程没用，而单核运算速度越快（主频高等），对单线程多线程都有提高（多线程可能是并发（被某个核cpu切换）,也可以能使并行（被多个核利用）)。


什么时候用多线程
a.多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置。
b.单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。
c.单核CPU——IO密集型任务，使用多线程还是为了人机交互方便，
d.多核CPU——IO密集型任务，这就更不用说了，跟单核时候原因一样。


提高运算速度的方法： 
a. CPU主频等属性
b. 多核下开多线程并行计算(单核下开多线程并发计算不能提高运算速度,只是为了多任务“同时”进行，还有避免等待的人际交互等）


如果连时钟阻塞、 线程切换这些功能我们都不需要了，自己在进程里面写一个逻辑流调度的东西。那么我们即可以利用到并发优势，又可以避免反复系统调用，还有进程切换造成的开销，分分钟给你上几千个逻辑流不费力。这就是用户态线程。


Python:
协成又称为微线程
OS是无法识别协程的，只能识别是线程，协成是由开发人员自己控制的。
协成可以在单线程下实现并发的效果（实际计算还是串行的方式）。
线程之间修改共享数据时，需要锁；而协成不需要，因为协成在线程中是串行的方式来修改数据的，所以不需要锁。
协程可以做到高并发、高扩展、低成本资源（一个CPU上万个协成都没问题）。
协程的缺点：
因为是在单线程中，所以无法利用多核CPU的资源；协程如果要使用多核CPU的话，那么就需要先启多个进程，在每个进程下启一个线程，然后在线程下在启协程。
在单线程下实现的并发效果，就是协程。


如果defer后面直接接一个语句如下，除了函数不会执行，参数表达式等会执行或用现在的值（也就是args如果你在后面赋值了，到defer的时候是赋值前的）
defer funcname(args)


str := "1234"
fmt.Println(str[4:]) //不报错
fmt.Println(str[5:]) //越界
fmt.Println(str[4]) //越界


url.ParseQuery("key=value&key=value&key=value") => url.Values //传入的不是整个url，而是rul参数部分， 如传入 /abc/nba?key1=value1&key2=value2 => key1会变成/abc/nba?key1
instead:
r, err := url.Parse("/abc/nba?key1=value1&key2=value2")
r.Query() => url.Values

form-data指multipart form, 是经过某种格式表示，有分隔符, 一般将文件作为另一种类型：
----------------------------399289160727635154297005
Content-Disposition: form-data; name="infocn"

text...
----------------------------399289160727635154297005
Content-Disposition: form-data; name="file"; filename="key.bak"
Content-Type: application/octet-stream

file content ...
----------------------------399289160727635154297005


x-www-form-urlencoded , 格式和url参数一样，只不过是放在body里， 参数值有些字符汇编编码如 &, /,...
两者都是放在body里，只是格式不一样, 带文件的一般都用第一种,





golang: interface{}类型转换不是正确类型时，一个参数接收转换后的值，会panic， 两个参数接收时，不会panic，第二个参数bool代表是否转换成功，
j := 5
var in interface{}
in = "hello world"
j, _ = in.(int) // 不会panic, 转换失败j值置空置（这里为0）


err = json.Unmarshal 结构体字段和json字段匹配规则: 
1. 看tag, 有完全匹配: 结构体字段的有tag 里和 json里字段名 完全匹配（分大小写）, 优先赋值给该结构体字段
2. 看没有tag, 字段名有完全匹配: 1中没有满足的结构体字段，结构体字段里Key值(该字段没有json tag) 和json字段名完全匹配， 优先赋值给该结构体字段
3. 字段名(有tag的只能看tag)或tag不分大小写匹配: 2中没有满足的结构体字段，结构体字段名或tag值里和json字段名 不分大小写 匹配上的 第一个结构体(同样不带tag的可理解为他们的tag为结构体字段名字，然后直接取第一个 tag值和json字段名 不分大小写 匹配的)
4. 3中没有，则该json字段找不到对应的结构体字段
（一个json字段只可能会赋值给一个结构体字段，即优先的，其他满足的不会赋值，在赋值的时候，类型不匹配会 err ！= nil, 找不到（第4步）不会error，因为没有走到赋值这一步）

json.Marshal比较简单：
有tag用tag名，没tag用字段名

u, err := url.Parse(...)
u.Query() //会返回一个新的url.Values !!!


map是 真×引用传递, 引用赋值，要copy另一份map只能遍历赋值

len(x) : 得x数组的元素个数（长度），len一个字符串指[]byte的个数


typescript:
 - constructor的public参数会自动创建作为成员变量
 - 0xf00d, 0b1010, 0o744
 - 枚举值未赋值的在前一个枚举值+1,
	enum Color { Red = 1.1, Green}
	let c :Color = Color.Green
	console.log(c) //2.1
 - 枚举值（Number）可以作为索引，得枚举名称（字符串）
	enum Color { Red = 1.1, Green}
	let c :String = Color[2.1]
	console.log(c) //2.1


r.Header map[string][]string{} 是引用，r.Header.Get() r.Header.Set() 调用的是底层的数据结构，r.Header = 另一个新的map[string][]string时，r.Header.Get等方法不会取新的，会取原来的，导致不一致



js作用域篇:
var: 
var声明的变量在所在的function, module, namespace, or global scope 都会被提前(赋值不提前)，也就是所某个变量被var声明时，无论他在哪，第一行，100行，都会被提到最上面，且不赋值; 且无论var作用在同一个变量几次，都一样, 所以var没有块作用域
如：

行数
...
...
100 var foo = 5;
相当于：
1   var foo;
...
100 foo = 5;



var 没有块作用域导致的问题：
for (var i=0; i<10; i++) {
    setTimeout(function() { console.log(i); }, 100 * i);
}
相当于(上面说到的var提升)：
var i;
...
for (i=0; i<10; i++){
...
}
// output: 10 10 10 ... 10
用var的话就只会有一个i变量,那么在第一个循环体开始执行settimeout的函数时，循环体早就结束了，i的值是10,所有都输出10


for (let i=0; i<10; i++) {
    setTimeout(function() { console.log(i); }, 100 * i);
}
//output: 1 2 3 4 ... 10 
for初始化用let声明的变量，作用域是循环体和收尾(块作用域)，且其他次循环体的i无法改变当前循环体i的值，互不影响: 当第一次进入循环体，至离开第一次循环体(包括收尾语句),则第二次循环体的i是另一个单独的局部变量，他的值为离开第一次循环体时i的只，之后第一次循环体的i值改变，不影响第二次循环的i，第二次循环的i值的改变也不影响第一次循环体的i(事实上执行几次循环，就会创建多少个i变量, 这一点和其他语言又不一样，golang也是块作用域，但是for的i也只会有一个)



============================================================
for (let i=0; i<10; i++) {
    setTimeout(function() { console.log(i); }, 100 * i);
}
有点像：
for (var i=0; i<10; i=++ii) {
    let ii = i;
    setTimeout(function() { console.log(ii); }, 100 * ii);
}
============================================================
for (var i=0; i<10; i++) {
    setTimeout(function() { console.log(i); }, 100 * i);
}
有点像：
for(let i = 0; i < 10;i=++a) {
    var a = i; //被提升
    setTimeout(function() { console.log(a); }, 1000 * a);
}
============================================================
没有let的时候怎么办： (让i进入另一个函数作用域）
for (var i = 0; i < 10; i++) {
    (function(i) {
        setTimeout(function() { console.log(i); }, 100 * i);
    })(i);
}


使用sqlite3驱动的memory模式注意业务更新你插入的记录
